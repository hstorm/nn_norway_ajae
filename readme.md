---
contributors:
  - Hugo Storm
  - Thomas Heckelei
  - Kathy Baylis
  - Klaus Mittenzwei
---

## Overview

> INSTRUCTIONS: The typical README in social science journals serves the purpose of guiding a reader through the available material and a route to replicating the results in the research paper. Start by providing a brief overview of the available material and a brief guide as to how to proceed from beginning to end.

Example: The code in this replication package constructs the analysis file from the three data sources (Ruggles et al, 2018; Inglehart et al, 2019; BEA, 2016) using Stata and Julia. Two main files run all of the code to generate the data for the 15 figures and 3 tables in the paper. The replicator should expect the code to run for about 14 hours.

## Data Availability and Provenance Statements

> INSTRUCTIONS: Every README should contain a description of the origin (provenance), location and accessibility (data availability) of the data used in the article. These descriptions are generally referred to as "Data Availability Statements" (DAS). However, in some cases, there is no external data used.

- [ ] This paper does not involve analysis of external data (i.e., no data are used or the only data are generated by the authors via simulation in their code).

> If box above is checked and if no simulated/synthetic data files are provided by the authors, please skip directly to the section on [Computational Requirements]. Otherwise, continue.

> INSTRUCTIONS: 
> - When the authors are **secondary data users** (they did not generate the data), the provenance and DAS coincide, and should describe the condition under which (a) the current authors (b) any future users might access the data. 
> - When the data were generated (by the authors) in the course of conducting (lab or field) **experiments**, or were collected as part of **surveys**, then the description of the provenance should describe the data generating process, i.e., survey or experimental procedures:
>   - Experiments: complete sets of experimental instructions, questionnaires, stimuli for all conditions, potentially screenshots, scripts for experimenters or research assistants, as well as for subject eligibility criteria (e.g. selection criteria, exclusions), recruitment waves, demographics of subject pool used. 
>   - For lab experiments specifically, a description of any pilot sessions/studies, and computer programs, configuration files, or scripts used to run the experiment. 
>   - For surveys, the whole questionnaire (code or images/PDF) including survey logic if not linear, interviewer instructions, enumeration lists, sample selection criteria.
>
>  The information should describe ALL data used, regardless of whether they are provided as part of the replication archive or not, and regardless of size or scope. The DAS should provide enough information that a replicator can obtain the data from the original source, even if the file is provided. 
>
> For instance, if using GDP deflators, the source of the deflators (e.g. at the national statistical office) should also be listed here. If any of this information has been provided in a pre-registration, then a link to that registration may (partially) suffice.
>
> DAS can be complex and varied. Examples are provided [here](https://social-science-data-editors.github.io/guidance/Requested_information_dcas.html), and below.
>
> Importantly, if providing the data as part of the replication package, authors should be clear about whether they have the **rights** to distribute the data. Data may be subject to distribution restrictions due to sensitivity, IRB, proprietary clauses in the data use agreement, etc.
>
> NOTE: DAS do not replace Data Citations (see [Guidance](Data_citation_guidance.md)). Rather, they augment them. Depending on journal requirements and to some extent stylistic considerations, data citations should appear in the main article, in an appendix, or in the README. However, data citations only provide information **where** to find the data, not **how to access** those data. Thus, DAS augment data citations by going into additional detail that allow a researcher to assess cost, complexity, and availability over time of the data used by the original author.

### Statement about Rights

- [ ] I certify that the author(s) of the manuscript have legitimate access to and permission to use the data used in this manuscript. 
- [ ] I certify that the author(s) of the manuscript have documented permission to redistribute/publish the data contained within this replication package. Appropriate permission are documented in the [LICENSE.txt](LICENSE.txt) file.


### (Optional, but recommended) License for Data

> INSTRUCTIONS: Most data repositories provide for a default license, but do not impose a specific license. Authors should actively select a license. This should be provided in a LICENSE.txt file, separately from the README, possibly combined with the license for any code. Some data may be subject to inherited license requirements, i.e., the data provider may allow for redistribution only if the data is licensed under specific rules - authors should check with their data providers. For instance, a data use license might require that users - the current author, but also any subsequent users - cite the data provider. Licensing can be complex. Some non-legal guidance may be found [here](https://social-science-data-editors.github.io/guidance/Licensing_guidance.html). For multiple licenses within a data package, the `LICENSE.txt` file might contain the concatenation of all the licenses that apply (for instance, a custom license for one file, plus a CC-BY license for another file).
>
> NOTE: In many cases, it is not up to the creator of the replication package to simply define a license, a license may be *sticky* and be defined by the original data creator.

*Example:* The data are licensed under a Creative Commons/CC-BY-NC license. See LICENSE.txt for details.


### Summary of Availability

- [ ] All data **are** publicly available.
- [ ] Some data **cannot be made** publicly available.
- [ ] **No data can be made** publicly available.

### Details on each Data Source

> INSTRUCTIONS: For each data source, list the file that contains data from that source here; if providing combined/derived datafiles, list them separately after the DAS. For each data source or file, as appropriate, 
> 
> - Describe the format (open formats preferred, but some software-specific formats OK if open-source readers available): `.dta`, `.xlsx`, `.csv`, `netCDF`, etc.
> - Provide a data dictionairy, either as part of the archive (list the file name), or at a URL (list the URL). Some formats are self-describing *if* they have the requisite information (e.g., `.dta` should have both variable and value labels).
> - List availability within the package
> - Use proper bibliographic references in addition to a verbose description (and provide a bibliography at the end of the README, expanding those references)
>
> A summary in tabular form can be useful:

| Data.Name  | Data.Files | Location | Provided | Citation |
| -- | -- | -- | -- | -- | 
| “Current Population Survey 2018” | cepr_march_2018.dta | data/ | TRUE | CEPR (2018) |
| “Provincial Administration Reports” | coast_simplepoint2.csv; rivers_simplepoint2.csv; RAIL_dummies.dta; railways_Dissolve_Simplify_point2.csv | Data/maps/ | TRUE | Administration (2017) |
| “2017 SAT scores” | Not available | data/to_clean/ | FALSE | College Board (2020) |

where the `Data.Name` column is then expanded in the subsequent paragraphs, and `CEPR (2018)` is resolved in the References section of the README.

### Example for public use data collected by the authors

> The [DATA TYPE] data used to support the findings of this study have been deposited in the [NAME] repository ([DOI or OTHER PERSISTENT IDENTIFIER]). [[1](https://www.hindawi.com/research.data/#statement.templates)]. The data were collected by the authors, and are available under a Creative Commons Non-commercial license.

### Example for public use data sourced from elsewhere and provided

> Data on National Income and Product Accounts (NIPA) were downloaded from the U.S. Bureau of Economic Analysis (BEA, 2016). We use Table 30. Data can be downloaded from https://apps.bea.gov/regional/downloadzip.cfm, under "Personal Income (State and Local)", select CAINC30: Economic Profile by County, then download. Data can also be directly downloaded using  https://apps.bea.gov/regional/zip/CAINC30.zip. A copy of the data is provided as part of this archive. The data are in the public domain.

Datafile:  `CAINC30__ALL_AREAS_1969_2018.csv`

### Example for public use data with required registration and provided extract

> The paper uses IPUMS Terra data (Ruggles et al, 2018). IPUMS-Terra does not allow for redistribution, except for the purpose of replication archives. Permissions as per https://terra.ipums.org/citation have been obtained, and are documented within the "data/IPUMS-terra" folder.
>> Note: the reference to "Ruggles et al, 2018" would be resolved in the Reference section of this README, **and** in the main manuscript.

Datafile: `data/raw/ipums_terra_2018.dta`

### Example for free use data with required registration, extract not provided

> The paper uses data from the World Values Survey Wave 6 (Inglehart et al, 2019). Data is subject to a redistribution restriction, but can be freely downloaded from http://www.worldvaluessurvey.org/WVSDocumentationWV6.jsp. Choose `WV6_Data_Stata_v20180912`, fill out the registration form, including a brief description of the project, and agree to the conditions of use. Note: "the data files themselves are not redistributed" and other conditions. Save the file in the directory `data/raw`. 

>> Note: the reference to "Inglehart et al, 2018" would be resolved in the Reference section of this README, **and** in the main manuscript.

Datafile: `data/raw/WV6_Data_Stata_v20180912.dta` (not provided)

### Example for confidential data

> INSTRUCTIONS: Citing and describing confidential data, in particular when it does not have a regular distribution channel or online landing page, can be tricky. A citation can be crafted ([see guidance](https://social-science-data-editors.github.io/guidance/FAQ.html#data-citation-without-online-link)), and the DAS should describe how to access, whom to contact (including the role of the particular person, should that person retire), and other relevant information, such as required citizenship status or cost.

> The data for this project (DESE, 2019) are confidential, but may be obtained with Data Use Agreements with the Massachusetts Department of Elementary and Secondary Education (DESE). Researchers interested in access to the data may contact [NAME] at [EMAIL], also see www.doe.mass.edu/research/contact.html. It can take some months to negotiate data use agreements and gain access to the data. The author will assist with any reasonable replication attempts for two years following publication.

### Example for confidential Census Bureau data

> All the results in the paper use confidential microdata from the U.S. Census Bureau. To gain access to the Census microdata, follow the directions here on how to write a proposal for access to the data via a Federal Statistical Research Data Center: https://www.census.gov/ces/rdcresearch/howtoapply.html. 
You must request the following datasets in your proposal:
>1. Longitudinal Business Database (LBD), 2002 and 2007
>2. Foreign Trade Database – Import (IMP), 2002 and 2007
[...]

(adapted from [Fort (2016)](https://doi.org/10.1093/restud/rdw057))

### Example for preliminary code during the editorial process

> Code for data cleaning and analysis is provided as part of the replication package. It is available at https://dropbox.com/link/to/code/XYZ123ABC for review. It will be uploaded to the [JOURNAL REPOSITORY] once the paper has been conditionally accepted.

## Dataset list

Data files used in the analysis, see variable code book below.

| Data file | Source | Notes    |Provided |
|-----------|--------|----------|---------|
| `data/raw/balancedPanel.csv` | NIBIO | As per terms of use | Yes |
| `data/raw/bunn.csv` | Referansebruksberegninger  | As per terms of use | Yes |
| `data/raw/grovfac.csv` | Veiledningshefte, www.slf.dep.no   | As per terms of use | Yes |
| `data/raw/importEAAPrices.csv` |   | As per terms of use | Yes |
| `data/raw/maks.csv` | Referansebruksberegninger  | As per terms of use | Yes |
| `data/raw/satser.csv` | Referansebruksberegninger  | As per terms of use | Yes |
| `data/raw/trin.csv` | Referansebruksberegninger  | As per terms of use | Yes |

Source Referansebruksberegninger: https://nibio.brage.unit.no/nibio-xmlui/discover?rpp=10&etal=0&query=REFERANSEBRUKSBEREGNINGER&group_by=none&page=1


#### Codebook  `data/raw/satser.csv`:
| Code| Description |
|-----------|--------|
| year | year|
| cat_sub | category of subsidy |
| cat_act | activity |
| step | step of subsidy |
| zone | zone of subsidy |
| rate | rate per head or area |


#### Codebook `data/raw/trin.csv`
| Code| Description |
|-----------|--------|
| year | year|
| cat_sub | category of subsidy |
| cat_act | activity |
| step | step of subsidy |
| cut | Upper limit of step |

#### Codebook `data/raw/maks.csv`
| Code| Description |
|-----------|--------|
| year | year|
| cat_sub | category of subsidy |
| rate | Upper limit of payments for TVELF and TPROD payments |

#### Codebook `data/raw/bunn.csv`
| Code| Description |
|-----------|--------|
| year | year|
| cat_sub | category of subsidy |
| rate | Overall discount deducted from the TAKTL payments (Bunnfradrag) |

#### Codebook `data/raw/grovfac.csv`
| Code| Description |
|-----------|--------|
| year | year|
| cat_sub | category of subsidy |
| cat_act | activity |
| zone | zone of subsidy |
| rate | rate per head or area |

#### Codebook `data/raw/balancedPanel.csv`
| Code| Description |
|-----------|--------|
| KGB | farm identifier (encoded) | 
| year | year| 
| knr | region number | 
| age | age of farmer in years| 
| x1 | Apples (kg)| 
| x2 | Pears (kg)| 
| x3 | Plums (kg)| 
| x4 | Cherries ( Prunus avium) sweet (kg)| 
| x5 | Cherries (Prunus cerasus) sour (kg)| 
| x6 | Apples/ Pears (kg)| 
| x11 | Strawberries (kg)| 
| x12 | Raspberries (kg)| 
| x13 | Blackcurrant (kg)| 
| x14 | Currants (kg)| 
| x16 | Blueberries (kg)| 
| x21 | Gooseberry (kg)| 
| x31 | Tomato (kg)| 
| x32 | Cucumber (kg)| 
| x33 | Lettuce (head) | 
| x60 | Potatoes (kg) | 
| x111 | adult horses | 
| x112 | other horses | 
| x113 | young horses under 2 yrs | 
| x114 | horses for breeding | 
| x115 | Horses under 3 years | 
| x116 | Horses over 3 years | 
| x120 | Dairy cows |
| x121 | Suckler cows for special meat production |
| x133 | Sheep or lamb which is kept outside most of the year| 
| x136 | Lamb (i.e., sheep under 1 year) that is kept inside during vinter | 
| x140 | Female goat over 1 year /Milkgoat |
| x142 | Suckler goats for special meat production | 
| x155 | Sows for breeding with minimum one litter |
| x157 | Slaughter pigs| 
| x160 | Laying hens at counting date / over 20 weeks |
| x180 | rabbits | 
| x181 | Deer farming, own manufactured grassland | 
| x183 | Ostrich | 
| x186 | Poultry sold as living animal | 
| x192 | Donkey | 
| x193 | Horses in pens. In the grazing season | 
| x196 | lama | 
| x197 | alpaca | 
| x230 | Potatoes |
| x235 | Meadow seed and other seed production | 
| x236 | Peas, beans and other legumes to… (mature?) | 
| x237 | Oil seeds | 
| x238 | Rye and rye wheat | 
| x239 | Grain to crush | 
| x240 | Wheat (Spring Wheat) | 
| x242 | Barley | 
| x243 | Oats | 
| x245 | Peas and beans to konserves | 
| x246 | Meadow seed, seeds, peas and beans ripening, Flaxseed | 
| x247 | Autumn Wheat | 
| x248 | Oil seeds seeded in autumn | 
| x249 | rye wheat | 
| x410 | Dairy Cows on outlying fields | 
| x411 | Dairy Cows on meadow | 
| x420 | Other livestock on outlying fields /Young cattle | 
| x422 | Other livestock on meadow 12/16 weeks, Young cattle | 
| x440 | Goat on outlying fields | 
| x445 | Goat on meadow 12/16 weeks| 
| x450 | Horses on rangeland | 
| x471 | lam slaughter 2011, quality 0 or better | 
| x473 | lam slaughter 2011, quality 0- | 
| x474 | lam slaughter 2011, quality P+ or worse | 
| x475 | KJE slaughter 2011, weight over 3,5 kg | 
| x487 | Sheep on meadow 1 year or older on meadow 12/16 weeks | 
| x488 | Lamb and sheep under 1 year old on meadow 12/16 weeks| 
| x521 | Sale of feed, High (kg) | 
| x522 | Sale of feed,  silage (kg) | 
| x523 | haylage (kg) | 
| x832 | slaugher pigs, pigs intendend for breeding | 
| x841 | laying hens | 
| CERE | Cereals (Codes: 235, 236, 237,238,239,240,242,243,245,246,247,248,249) |
| GEIT | male goat (Codes: 141,143,144) |
| GRON | Vegetables outside (Codes: 260,263,264) |
| SAU | Sheep (Codes: 130, 137 and 149) |
| STOR | Other Cattle (Codes: 119,122,123,124,125,126,127,128,129) |
| BAER | Berries (Codes: 280, 281, 282, 283)| 
| FODD | Fodder (210,211,212) | 
| FRUK | Fruits (Codes: 271, 272, 273, 274)| 
| HEST | Horses (Codes: 111,112, 113,114,115,116) | 
| USAU | Sheep on outlying fields (Codes: 430,431,432,437,438)| 
| VSAU | Sheep kept inside during winter (Codes: 134,135,145,146) | 
| x210 | Fodder on arable land | 
| x211 | Fodder (pasture) on arable non-fenced land | 
| x212 | Fodder on non-arable fenced land | 
| x213 | Other fodder | 
| zoneTAKTL | zone relevant for TAKTL subsidies | 
| zoneTDISE | zone relevant for TDISE subsidies | 
| zoneTDISG | zone relevant for TDISG subsidies | 
| zoneTDISK | zone relevant for TDISK subsidies | 
| zoneTDISM | zone relevant for TDISM subsidies | 
| zoneTDMLK | zone relevant for TDMLK subsidies | 
| zoneTPROD | zone relevant for TPROD subsidies | 
| birthyear | year of birth farmer| 


## Computational requirements

To replicate the software environment, use the provided Dockerfile. You can either pull the image from Docker Hub or build it yourself.


#### Pull docker image from Docker Hub
TODO: Add docker hub link

#### Rebuild docker image locally
Build docker image: `docker build -t nn_norway_ajae:1.0 .`

#### Run docker image
To Start container: `docker run --gpus all -it nn_norway_ajae:1.0`

Once the container is running, you can attach a shell and run the code as described below.

### Software Requirements

Software requirements are listed in the `Dockerfile`. Python requirements are listed in `requirements_docker.txt`.
When using the provided docker image from Docker Hub, all software requirements are installed.


### Controlled Randomness

Controlling of randomness is not fully possible when training on a GPU, one reason is that controlling randomness would required a exactly equal hardwar setup.

### Memory and Runtime Requirements

Training of the model can best be performed using a single GPU (e.g. NVIDIA RTX A5000) but training on a CPU is also possible. 

## Description of programs/code

Organization of the code largely follows the Cookiecutter Data Science template (https://drivendata.github.io/cookiecutter-data-science/)

Most important parts are:
- Programs in `src/features` are used to prepare the features. 
- Programs in `src/models` are used to train models and perform the post-model analysis and to prepare the results. 

### License for Code

The code is licensed under a MIT license. See [LICENSE.txt](LICENSE.txt) for details.

## Instructions to Replicators


#### Build dataset 
On a first run the dataset needs to be build. This can be done by running the following programs in the following order:

Open two shells (at the same time) and run
1) `scl enable rh-python36 -- python luigid`
2) `scl enable rh-python36 -- python src/features/luigi_features.py`

For details refer to the in-code documentation in: `src/features/luigi_features.py` and `src/features/calc_dpay.py`


#### Train a model
To train a model run the following program:
`scl enable rh-python36 -- python src/models/nn_model.py` 


### Details

To reproduce the results in the paper use the trained model to create the figures (see commands below). The ID of the model used for the paper is `15283bd4-51d2-11ec-8639-0242ac110003`, stored under `models`. 

If a new model is trained a new model ID is created (see the output after model training). The new model will also be stored under `models`. To create the figures with the newly trained model, replace the model ID in `src/models/nn_shap.py` and `src/models/nn_scenarios.py` in the __main__ function before creating the outputs below.


## List of tables and programs

The provided code reproduces:

- [ ] All numbers provided in text in the paper
- [ ] All tables and figures in the paper
- [x] Selected tables and figures in the paper, as explained and justified below.

The code allows to reproduce all the main figures showing the model outcomes which are the bases for the results section.  


#### Calculate SHAP feature importance (Figure 4 & 5)
Run: `scl enable rh-python36 -- python src/models/nn_shap.py` 

This provide the plots for Figure 4 and 5

Figure 4 results are stored under: `reports/figures/[modelID]/shap/featureImportance_relative_[modelID]_shortTimeSuffel_.png`

Figure 5 results are stored under: 
`reports/figures/[modelID]/shap/featureImportance_time_[modelID]_shortTimeSuffel_SAU_numFeat40mask.png`
and
`reports/figures/[modelID]/shap/featureImportance_time_[modelID]_shortTimeSuffel_SAU_numFeat40mask.png`


#### Create scenario simulations  (Figures 6 & 7)
Run: `scl enable rh-python36 -- python src/models/nn_scenario.py` 

This provide the plots for Figure 6 and 7 

Individual plots are in stored folder `reports/figures/[modelID]/scenarios/`

For Figure 6 the following plots are used:
| Scenario flat rate "Sheep" | Scenario size discriminatory "Sheep" |
|-------------------|--------------------------|
| `[modelID]_flat_tprod_SAU_prev_SAU_CsubD1_SAU.png` | `[modelID]_increase_tprod_SAU_prev_SAU_CsubD1_SAU.png` |
| `[modelID]_flat_tprod_SAU_prev_SAU_DAvgSub_SAU.png` | `[modelID]_increase_tprod_SAU_prev_SAU_DAvgSub_SAU.png`  |
| `[modelID]_flat_tprod_SAU_prev_SAU_SAU.png` | `[modelID]_increase_tprod_SAU_prev_SAU_SAU.png` |

For Figure 7 the following plots are used:
| Scenario flat rate "Dairy" | Scenario size discriminatory "Dairy" |
|-------------------|--------------------------|
| `[modelID]_flat_tprod_x120_prev_x120_CsubD1_x120.png` | `[modelID]_increase_tprod_x120_prev_x120_CsubD1_x120.png` |
| `[modelID]_flat_tprod_x120_prev_x120_DAvgSub_x120.png` | `[modelID]_increase_tprod_x120_prev_x120_DAvgSub_x120.png`  |
| `[modelID]_flat_tprod_x120_prev_x120_x120.png` | `[modelID]_increase_tprod_x120_prev_x120_x120.png` |



---

## Acknowledgements

This readme was created following the guidlines from [Hindawi](https://social-science-data-editors.github.io/template_README/).